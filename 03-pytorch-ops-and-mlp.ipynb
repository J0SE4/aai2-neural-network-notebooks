{"cells":[{"cell_type":"markdown","metadata":{"id":"aa4htfWIcaGD"},"source":["# Experimenting with PyTorch"]},{"cell_type":"markdown","metadata":{"id":"vh5A8GZ_caGE"},"source":["For using PyTorch you can either use your own Computer or [Google Colab](https://colab.research.google.com/).\n","\n","You need to install the [PyTorch](https://pytorch.org/) package which comes with some extra dependencies.\n","\n","Install the following packages for this notebook:\n","- **PyTorch**\n","- **torchvision**\n","- **tqdm**\n","- **matplotlib**\n","\n","If your computer is equpped with a GPU you can also install the GPU version of PyTorch. Otherwise install the CPU version, which is smaller in size and enough for the tasks of this practical.\n","\n","For using the GPU version you need to fullfill some prerequisites first, which are a little time consuming.\n","- Make sure that your graphics card is new enough to handle the PyTorch environment. This can be checked by searching for the compute capability of your GPU and the compute capability requirements from the PyTorch module\n","- Install the latest NVIDIA driver\n","- Install suitable CUDA version\n","- Install CudNN\n","- Install PyTorch after all previous successful steps\n","\n","\n","Using Google Colab should avoid installing the above mentioned prerequisites."]},{"cell_type":"markdown","metadata":{"id":"Czyu-ak_caGF"},"source":["## PyTorch Operations"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sW4Y-XMWcaGF","executionInfo":{"status":"ok","timestamp":1762541413437,"user_tz":-60,"elapsed":15,"user":{"displayName":"José Solano","userId":"14867739661723897543"}},"outputId":"9ad2ffa4-6997-4138-f3f6-619ff7f8f636"},"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([ 0.3450,  1.6843, -1.2802,  1.1890,  0.0053,  0.1784])\n","<class 'numpy.ndarray'>\n","<class 'torch.Tensor'>\n","Shape: torch.Size([6])\n","Dtype: torch.float32\n","Device: cpu\n","First 3 elements:  tensor([ 0.3450,  1.6843, -1.2802])\n","Last 2 items:  tensor([0.0053, 0.1784])\n","A:  tensor([[ 0.2096, -0.1398,  0.7430, -0.1176],\n","        [ 1.2773, -0.8067, -0.1640,  0.4523],\n","        [ 1.3233,  0.5538, -0.0072,  0.1421]])\n","B:  tensor([[0.1322, 0.1390],\n","        [0.4247, 0.2203],\n","        [0.5879, 0.6027],\n","        [0.7173, 0.7620]])\n","Product:  tensor([[0.3208, 0.3565],\n","        [0.0542, 0.2457],\n","        [0.5077, 0.4099]])\n","X:  tensor([ 0.2991, -0.3461,  0.3332, -0.6016, -0.3709])\n","Y:  tensor([ 0.6312,  0.1567, -0.3592,  1.1931, -1.2336])\n","Hadamard:  tensor([ 0.1888, -0.0542, -0.1197, -0.7177,  0.4576])\n"]}],"source":["import torch\n","import torch.nn as nn\n","\n","# Tensors\n","\n","# Initialize a 1d torch tensor of size (6, 1) and name it 'data'. Initialize the tensor as random normal distribution\n","\n","# Code here\n","data = torch.randn(6)\n","print(data)\n","\n","\n","# Convert the torch tensor to a numpy array and convert it back afterwards. Keep the variable naming and just override the variable every time\n","\n","# Code here\n","data = data.numpy()\n","print(type(data))\n","\n","data = torch.from_numpy(data)\n","print(type(data))\n","\n","\n","# Tensors have a shape, a data type and are executed on some device on your computer. Find the mentioned tensor attributes and print them.\n","\n","# Code here\n","print(\"Shape:\", data.shape)\n","print(\"Dtype:\", data.dtype)\n","print(\"Device:\", data.device)\n","\n","\n","# Slicing works the same as with numpy arrays. No need to learn a new syntax here :)\n","# Try some slicing methods (i. e. the slicing methods we discussed in the first practical)\n","\n","# Code here\n","print(\"First 3 elements: \", data[:3])\n","print(\"Last 2 items: \", data[-2:])\n","\n","\n","###\n","# Arithmetic operations\n","###\n","\n","# Perform a matrix multiplication with two random tensors of different shape. The value initialization is of your choice.\n","\n","# Code here\n","a = torch.randn(3, 4)\n","print(\"A: \", a)\n","b = torch.rand(4, 2)\n","print(\"B: \", b)\n","product = torch.matmul(a, b)\n","print(\"Product: \", product)\n","\n","\n","# Perform the hadamard (element-wise) product with two random initialized tensors.\n","\n","# Code here\n","x = torch.randn(5)\n","print(\"X: \", x)\n","y = torch.randn(5)\n","print(\"Y: \", y)\n","hadamard = x * y\n","print(\"Hadamard: \", hadamard)\n","\n","\n","# For more useful tensor operations, plese check out their website: https://pytorch.org/tutorials/beginner/basics/tensorqs_tutorial.html"]},{"cell_type":"markdown","metadata":{"id":"I4CGk2QpcaGF"},"source":["## PyTorch Sequential and Layers"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"U7wSpunQcaGF","executionInfo":{"status":"ok","timestamp":1762542071771,"user_tz":-60,"elapsed":23,"user":{"displayName":"José Solano","userId":"14867739661723897543"}},"outputId":"9eee849f-6686-4167-ae47-96682ef90e4d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Linear(in_features=16, out_features=32, bias=True)\n","Parameter containing:\n","tensor([[-1.0078e-01,  2.2524e-01,  2.3846e-01, -2.3252e-02, -7.5677e-02,\n","          1.9492e-02,  1.2729e-01, -3.6136e-02,  1.1116e-02, -1.9664e-01,\n","          2.1670e-01, -1.6613e-01,  1.0787e-01, -1.2367e-01, -4.6541e-02,\n","          2.0568e-01],\n","        [-1.9012e-01, -1.1837e-01, -1.4882e-01, -6.8181e-02,  1.0847e-02,\n","         -1.7372e-01, -2.0631e-01,  1.2677e-01, -1.7200e-01, -2.4831e-01,\n","          2.0456e-01, -1.6486e-01,  8.9823e-02, -1.0133e-01, -9.5951e-02,\n","         -1.1860e-01],\n","        [-1.9087e-01,  8.6663e-02,  5.2202e-02, -9.8063e-02,  3.4352e-02,\n","         -2.4174e-01, -2.4769e-03,  4.8344e-02, -2.0510e-01, -1.4813e-01,\n","          1.2291e-01, -5.6834e-02, -1.7218e-01, -4.2249e-02,  2.3656e-01,\n","         -1.6434e-01],\n","        [ 1.3223e-01, -2.3329e-02, -4.0737e-02,  2.4712e-01, -1.5920e-01,\n","          6.0473e-02, -2.2926e-01,  3.6500e-02, -2.1308e-01, -1.3441e-01,\n","         -3.3670e-02, -1.1112e-01,  2.1370e-01, -1.9613e-01,  2.8365e-02,\n","         -1.2836e-01],\n","        [-1.0254e-01, -8.8805e-02, -1.0406e-01,  2.3032e-01, -1.5448e-01,\n","          1.6869e-01, -1.0234e-01,  1.9287e-01,  4.1600e-02, -1.3380e-01,\n","         -1.5818e-02,  1.1357e-01, -6.7372e-02, -1.7210e-01, -5.6639e-02,\n","          9.0292e-02],\n","        [ 8.4267e-02,  2.1413e-02,  1.0370e-01, -1.4303e-01, -2.4478e-02,\n","          8.2850e-05, -5.7836e-02,  2.1707e-01,  7.6580e-04,  2.3733e-01,\n","         -1.9691e-01, -7.8789e-02, -2.8177e-02, -1.6363e-01, -1.0636e-01,\n","         -2.0446e-01],\n","        [ 7.8579e-03,  1.6958e-01,  6.3760e-02, -8.9370e-02, -1.2341e-01,\n","         -2.1566e-01,  3.9823e-02,  3.6163e-02,  1.5115e-01, -3.1996e-03,\n","          8.0017e-02,  9.7560e-03, -1.2337e-01,  1.7307e-01, -1.0410e-01,\n","          2.8328e-02],\n","        [ 9.6069e-02,  2.0931e-01, -1.7512e-01,  1.3610e-01, -1.9341e-01,\n","         -7.4706e-02,  1.0688e-02,  2.2773e-01, -9.5541e-02, -1.3083e-01,\n","          1.0722e-01, -2.0348e-01, -2.9388e-02,  2.0159e-01,  1.6094e-01,\n","         -1.7712e-01],\n","        [-9.8623e-02,  1.3499e-01,  1.6031e-01,  1.3797e-01, -1.1948e-01,\n","         -2.1672e-01,  2.3487e-01,  1.3495e-01,  5.6004e-02,  8.8889e-02,\n","         -9.1646e-02, -6.8406e-02, -1.7634e-01,  1.6694e-01, -1.2325e-01,\n","          1.9316e-01],\n","        [ 1.3289e-01,  1.1965e-01, -7.1221e-02, -2.4669e-01,  2.0228e-01,\n","          2.0970e-01, -1.6725e-01, -2.6547e-02,  9.1851e-02,  1.8493e-01,\n","          5.5548e-02, -6.8272e-02, -6.9638e-02,  1.7785e-02, -1.9463e-01,\n","         -1.7244e-01],\n","        [ 2.0964e-01, -2.4861e-01, -7.6801e-02, -5.8475e-03, -9.3160e-03,\n","          3.8537e-02,  1.6183e-01, -1.1190e-01,  1.9507e-01,  3.2027e-02,\n","          9.2576e-02,  5.6202e-02, -1.7746e-01,  1.2047e-01, -6.6090e-02,\n","          1.7130e-01],\n","        [-5.3417e-02, -2.0156e-01,  9.3180e-02,  1.8984e-01,  1.3719e-01,\n","          1.6957e-01, -1.3622e-01,  1.0304e-01,  1.9563e-01,  8.9853e-02,\n","          2.3598e-01, -1.8331e-01, -1.0362e-01, -1.9356e-01,  1.0434e-01,\n","         -1.5848e-01],\n","        [ 2.4692e-01, -8.3067e-02,  1.1396e-01,  2.0223e-01, -5.8944e-02,\n","         -1.7245e-01, -2.0823e-01,  3.3920e-02, -4.9406e-02,  1.0048e-01,\n","          1.9609e-01,  1.2949e-01, -2.9798e-02, -6.9813e-02,  1.5121e-01,\n","         -1.1916e-01],\n","        [ 2.2757e-01,  1.7557e-01, -2.4676e-01, -9.5126e-02,  2.3317e-01,\n","          1.8591e-01,  1.9415e-01,  1.5363e-02,  6.8868e-03, -5.8514e-03,\n","          7.8036e-02, -9.1054e-02, -1.3863e-01,  5.0573e-02, -4.5977e-02,\n","          1.6176e-01],\n","        [-7.4294e-02,  1.8945e-01, -7.8823e-02,  1.9364e-01, -5.2045e-02,\n","         -1.9723e-01, -1.3963e-01, -9.3595e-02,  1.5777e-01,  1.8574e-01,\n","          2.0290e-01, -6.7716e-02, -2.2155e-01, -2.0992e-01, -7.9408e-02,\n","          9.3694e-02],\n","        [ 2.4058e-01,  1.9577e-01, -2.3228e-01, -9.5469e-04,  4.6194e-04,\n","         -1.1933e-01,  1.9903e-01, -1.0148e-02, -2.4054e-02,  2.1999e-01,\n","          1.1414e-02, -2.2652e-01, -3.5775e-03,  1.1212e-01, -1.3308e-01,\n","          2.1623e-01],\n","        [-1.5856e-01,  8.5766e-02,  1.0661e-01,  2.0636e-01,  1.5192e-01,\n","          7.9896e-02, -1.9304e-01,  9.1588e-02,  7.4075e-03, -1.2489e-01,\n","         -2.3228e-01,  2.8374e-02,  1.7424e-01, -1.8420e-01, -9.7132e-02,\n","          3.7330e-02],\n","        [ 6.8973e-03,  2.2730e-01,  1.4210e-01, -2.4840e-01,  1.2546e-01,\n","          3.9709e-02,  8.2924e-02, -1.7253e-01,  2.0571e-01,  1.8360e-01,\n","         -1.0417e-01, -1.9797e-01, -1.3357e-01, -1.4888e-01,  1.7235e-01,\n","         -6.0447e-03],\n","        [ 2.3627e-01,  9.7807e-02, -1.0550e-01,  8.9965e-03,  2.3459e-02,\n","         -1.2685e-01, -6.2191e-02, -2.4321e-01,  2.0969e-01,  3.6089e-02,\n","         -2.2835e-02, -2.2963e-01, -1.5007e-01,  2.0322e-01, -1.9535e-01,\n","          1.8102e-01],\n","        [-2.4838e-01, -1.0213e-01,  1.2856e-01, -1.2951e-01, -2.1048e-01,\n","          2.0271e-01, -1.7960e-01,  5.9452e-02,  1.7521e-01, -4.0279e-02,\n","         -2.2201e-01, -9.2189e-03,  2.4301e-01, -1.8076e-01, -1.0076e-01,\n","         -1.7397e-01],\n","        [-2.5319e-02,  3.9841e-02,  2.7178e-02, -2.0443e-01,  1.4927e-01,\n","          1.2631e-01,  4.0857e-02, -4.0250e-03, -2.2824e-01,  2.1039e-01,\n","         -1.2547e-01,  8.1522e-02,  8.8455e-02,  3.5968e-03, -1.8591e-02,\n","         -5.1745e-02],\n","        [-9.7919e-02, -5.8661e-02,  6.9221e-02,  1.4710e-01,  2.4022e-01,\n","         -2.4873e-01,  1.4532e-01, -1.8534e-01, -2.3165e-01,  2.5163e-02,\n","          1.0342e-01,  2.3767e-01, -4.3055e-03, -2.0788e-01,  1.3020e-01,\n","          1.8803e-01],\n","        [ 2.2479e-01, -2.8562e-02, -2.2034e-01, -2.2214e-01, -1.5333e-01,\n","          1.6282e-01,  8.6933e-02,  1.9396e-02,  8.0709e-02, -3.2084e-02,\n","         -1.5291e-01, -5.1229e-02,  2.3737e-01,  1.9509e-01,  1.1393e-01,\n","         -2.2713e-02],\n","        [ 1.8337e-01,  2.1682e-01, -1.9911e-01, -4.7540e-02, -1.8583e-02,\n","          1.8195e-01, -1.9984e-01, -8.0196e-02,  2.1468e-01, -1.2341e-03,\n","         -1.8276e-01, -5.5439e-03,  1.7192e-01,  2.1585e-01, -1.6586e-01,\n","          7.4368e-02],\n","        [-1.8056e-01, -9.3962e-02,  2.2170e-01, -5.9668e-02, -8.9172e-02,\n","          3.3707e-02,  1.3707e-01,  3.0831e-02,  1.3307e-01,  2.4794e-01,\n","         -1.6537e-01,  3.4716e-03, -1.5515e-01,  1.6629e-01, -1.2387e-01,\n","          2.2396e-01],\n","        [ 5.3631e-02, -1.8952e-01, -8.9350e-02, -7.3580e-02, -6.1897e-02,\n","         -5.3590e-02,  5.3666e-02,  1.2624e-01, -6.3060e-02,  1.0229e-01,\n","          5.7482e-03,  2.4149e-01, -4.8324e-02,  1.1331e-01,  1.8449e-01,\n","          2.5301e-02],\n","        [ 5.1684e-02,  1.7860e-01,  1.3614e-01, -4.1854e-02, -1.2125e-01,\n","         -7.6312e-02, -8.9149e-02,  5.8760e-02,  2.2833e-01, -5.8992e-02,\n","          1.7810e-01, -1.6358e-01,  2.9986e-02, -1.8893e-01,  9.1535e-02,\n","          1.9360e-01],\n","        [-1.3020e-01, -2.4363e-01,  9.3055e-02, -2.3725e-01, -1.2341e-01,\n","         -1.0806e-02,  1.8578e-01, -7.5965e-02, -1.7508e-01, -5.4080e-02,\n","          6.1562e-02,  1.3451e-01,  4.7055e-02,  1.0141e-01,  2.8606e-02,\n","          1.7281e-01],\n","        [-1.4740e-01,  1.0564e-01, -1.9430e-01,  3.4402e-02,  3.5905e-02,\n","          4.1154e-02,  1.5317e-01, -1.7617e-01, -6.2701e-02,  2.1378e-02,\n","          1.8261e-01,  6.5858e-02, -1.4164e-01, -2.4295e-02,  6.5940e-02,\n","          1.8376e-01],\n","        [ 1.2010e-01,  1.2778e-02,  2.9448e-02, -1.5425e-02,  1.6383e-01,\n","         -2.3710e-02,  1.6136e-01, -1.4525e-01,  2.1121e-01,  1.5357e-02,\n","          1.5693e-01,  1.6211e-01, -1.1788e-01,  2.9743e-02, -1.2118e-01,\n","         -2.0209e-02],\n","        [ 4.6867e-03,  7.2167e-02,  1.3138e-01, -2.2845e-01,  1.7283e-01,\n","          1.1315e-01, -3.6443e-02, -3.0340e-02,  2.1341e-01,  5.1503e-03,\n","          4.7413e-02, -5.2089e-02, -2.3005e-01, -3.9696e-03, -1.8579e-02,\n","         -2.6463e-02],\n","        [ 2.7508e-02,  1.9466e-01,  1.8162e-02,  8.2077e-02,  7.6543e-02,\n","          5.6385e-02, -1.6019e-01, -6.2378e-02,  8.4066e-04,  7.0041e-02,\n","         -2.3966e-01,  2.1136e-01, -4.7079e-02,  1.4901e-01, -5.3164e-02,\n","         -1.1715e-02]], requires_grad=True)\n","torch.Size([4, 32])\n"]}],"source":["# We now build our first neural network layers and combine them into one model\n","\n","# First lets define an example Linear layer.\n","# Initialize a Linear layer from PyTorch of dimension (in_features=16, out_features=32).\n","\n","# Code here\n","layer = nn.Linear(16, 32)\n","\n","\n","# Print the layer attributes and print the weight of the Linear layer\n","# Forward a fitting random initialized 2d tensor through the layer and print the result\n","# What is the shape of the passed (forwarded) random tensor?\n","\n","# Code here\n","print(layer)\n","print(layer.weight)\n","input_tensor = torch.randn(4, 16)\n","output_tensor = layer(input_tensor)\n","print(output_tensor.shape)\n","\n","\n","# Why does it work to just call an initialized layer by initialized_layer(input)?\n","# Check the source code for the Linear Layer and its parent 'Module' class here: https://pytorch.org/docs/stable/_modules/torch/nn/modules/linear.html#Linear\n","# Explain in your own words why the forward function of the 'Linear' class is automatically called when passing an input through the layer, i. e. initialized_layer(input)\n","# Hint: Check out the class inheritance!\n","\n","# Your explanation here\n","# When you call an initialized layer by passing an input tensor, the __call__ method of the parent nn.Module class automatically\n","# calls the forward() method, so you don't need to explicitly call forward()\n","\n","\n","# Build a sequential model with some linear layers stacked after each other. The number of layers is your choice, but be careful because it could cost a lot of time\n","# to pass data through the sequential model afterwards. Start e. g. with three linear layers :)\n","# You are not restricted to linear layers. Experiment a little bit here!\n","\n","# Code here\n","model = nn.Sequential(\n","    nn.Linear(784, 32),  # input layer (do not change the in_features size of this layer - we need it later)\n","    # your layers\n","    nn.ReLU(),\n","    nn.Linear(32, 10)  # you can change the in_features of this layer but let the out_features at size 10 here - we need it layer\n",")\n"]},{"cell_type":"markdown","metadata":{"id":"6R_o0I4ncaGF"},"source":["## PyTorch Forward Pass"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":482},"id":"D--DGG-vcaGF","executionInfo":{"status":"ok","timestamp":1762542407692,"user_tz":-60,"elapsed":104,"user":{"displayName":"José Solano","userId":"14867739661723897543"}},"outputId":"bdaa17e2-b03e-4223-9e8d-c112d67554dd"},"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([5, 10])\n","torch.Size([1, 28, 28])\n","torch.Size([1, 10])\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 640x480 with 1 Axes>"],"image/png":"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\n"},"metadata":{}}],"source":["# We initialized our model in the previous section\n","# Lets now also use the model to pass data through it\n","\n","# Use the following tensor and pass it through your model from above\n","# You have to 'reformat' the tensor first\n","data = torch.randn(size=(5, 1, 28, 28))\n","\n","# Code here\n","output = model(data.view(5, -1))\n","print(output.shape)\n","\n","# read the image 'mnist_9.jpg' from the downloaded folder with the 'torchvision' python package and pass it through the network\n","# How does the tensor of the image looks like? Which information is in the different dimensions?\n","\n","# Code here\n","from PIL import Image\n","from torchvision import transforms\n","\n","img = Image.open('mnist_9.jpg')\n","tensor_img = transforms.ToTensor()(img)\n","output_img = model(tensor_img.view(1, -1))\n","print(tensor_img.shape)\n","print(output_img.shape)\n","\n","\n","\n","# visualize the image from above with matplotlib\n","import matplotlib.pyplot as plt\n","\n","# Code here\n","plt.imshow(tensor_img.squeeze(), cmap='gray')\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"7FgZs4TJcaGF"},"source":["## PyTorch Neural Network Example Implementation"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lKMhq0macaGG","executionInfo":{"status":"ok","timestamp":1762542948281,"user_tz":-60,"elapsed":530617,"user":{"displayName":"José Solano","userId":"14867739661723897543"}},"outputId":"8ceadc3d-1423-46c7-8989-8c9ab331ab11"},"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 9.91M/9.91M [00:00<00:00, 19.0MB/s]\n","100%|██████████| 28.9k/28.9k [00:00<00:00, 510kB/s]\n","100%|██████████| 1.65M/1.65M [00:00<00:00, 4.72MB/s]\n","100%|██████████| 4.54k/4.54k [00:00<00:00, 8.73MB/s]\n","Training iteration 1: 100%|██████████| 15000/15000 [00:53<00:00, 282.88it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1 finished with loss: 0.446 and accuracy 0.867\n"]},{"output_type":"stream","name":"stderr","text":["Training iteration 2: 100%|██████████| 15000/15000 [00:52<00:00, 287.39it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 2 finished with loss: 0.358 and accuracy 0.895\n"]},{"output_type":"stream","name":"stderr","text":["Training iteration 3: 100%|██████████| 15000/15000 [00:51<00:00, 290.92it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 3 finished with loss: 0.340 and accuracy 0.900\n"]},{"output_type":"stream","name":"stderr","text":["Training iteration 4: 100%|██████████| 15000/15000 [00:52<00:00, 286.25it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 4 finished with loss: 0.326 and accuracy 0.905\n"]},{"output_type":"stream","name":"stderr","text":["Training iteration 5: 100%|██████████| 15000/15000 [00:53<00:00, 278.58it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 5 finished with loss: 0.313 and accuracy 0.909\n"]},{"output_type":"stream","name":"stderr","text":["Training iteration 6: 100%|██████████| 15000/15000 [00:52<00:00, 286.93it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 6 finished with loss: 0.303 and accuracy 0.911\n"]},{"output_type":"stream","name":"stderr","text":["Training iteration 7: 100%|██████████| 15000/15000 [00:52<00:00, 286.45it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 7 finished with loss: 0.296 and accuracy 0.914\n"]},{"output_type":"stream","name":"stderr","text":["Training iteration 8: 100%|██████████| 15000/15000 [00:52<00:00, 283.28it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 8 finished with loss: 0.289 and accuracy 0.915\n"]},{"output_type":"stream","name":"stderr","text":["Training iteration 9: 100%|██████████| 15000/15000 [00:52<00:00, 285.71it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 9 finished with loss: 0.284 and accuracy 0.917\n"]},{"output_type":"stream","name":"stderr","text":["Training iteration 10: 100%|██████████| 15000/15000 [00:52<00:00, 286.18it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 10 finished with loss: 0.275 and accuracy 0.920\n"]}],"source":["# This is only the application of your defined model\n","# You can use the following method to train your model and check its accuracy. You can also use parts of the code below for the following practicals.\n","# Just execute this box and it uses the predefined model from the previous task to run a training procedure. The variable name of the model must be 'model' (or change it accordingly).\n","# ATTENTION: No worries if you don't understand the implementation. This is just for showing you how your defined model performs in terms of accuracy.\n","\n","# Refine your model multiple times and see how the different models perform in terms of accuracy.\n","\n","# We use the MNIST dataset to set the model\n","import torchvision\n","import torchvision.transforms as transforms\n","import tqdm\n","\n","def load_mnist_data(root_path='./data', batch_size=4):\n","    transform = transforms.Compose(\n","        [transforms.ToTensor(),\n","        transforms.Normalize((0.5), (0.5))]\n","    )\n","\n","    trainset = torchvision.datasets.MNIST(root=root_path, train=True, download=True, transform=transform)\n","    trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=2)\n","\n","    testset = torchvision.datasets.MNIST(root=root_path, train=False, download=True, transform=transform)\n","    testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=2)\n","\n","    return trainloader  , testloader\n","\n","\n","def train_model(model, batch_size: int = 4, epochs: int = 10):\n","    # we only consider the mnist train data for this example\n","    train_loader, _ = load_mnist_data(root_path='./data', batch_size=batch_size)\n","\n","    device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n","\n","    model = model.to(device=device)\n","\n","    criterion = nn.CrossEntropyLoss()\n","    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n","\n","    for epoch in range(epochs):\n","        running_loss = 0.0\n","        running_accuracy = []\n","        for imgs, targets in tqdm.tqdm(train_loader, desc=f'Training iteration {epoch + 1}'):\n","            imgs, targets = imgs.to(device=device), targets.to(device=device)\n","\n","            # zero the parameter gradients\n","            optimizer.zero_grad()\n","\n","            # forward + backward + optimize\n","            outputs = model(imgs.reshape(imgs.shape[0], -1))\n","            loss = criterion(outputs, targets)\n","            loss.backward()\n","            optimizer.step()\n","\n","            # print statistics\n","            running_loss += loss.item()\n","\n","            # Calculate the Accuracy (how many of all samples are correctly classified?)\n","            max_outputs = torch.max(outputs, dim=1).indices\n","            accuracy = (max_outputs.detach() == targets.detach()).to(dtype=torch.float32).mean()\n","            running_accuracy.append(accuracy)\n","\n","        print(f'Epoch {epoch + 1} finished with loss: {running_loss / len(train_loader):.3f} and accuracy {torch.tensor(running_accuracy).mean():.3f}')\n","\n","\n","# Run the model training with the name of your model variable, in this case 'model'\n","train_model(model=model, batch_size=4, epochs=10)"]}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.6"},"vscode":{"interpreter":{"hash":"25301cabe4c6f833fd20f15b1b22933971919908771eb627a83fe325b4fb6671"}},"colab":{"provenance":[{"file_id":"1FDjk3xSCIzQlLd7-w0b5DPR1blLV4QYk","timestamp":1762551765405}],"gpuType":"T4"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}