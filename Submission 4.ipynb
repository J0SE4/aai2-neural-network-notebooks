{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CrdD-_5dWJxi"
      },
      "source": [
        "# Weight Initialization"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "id": "4SLd4Z4jWJxj"
      },
      "source": [
        "We need the Python packages for PyTorch and matplotlib for this exercise."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lLlTX-NWWJxj"
      },
      "source": [
        "## Our test model for this practical task"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "PUYfjON5WJxj"
      },
      "outputs": [],
      "source": [
        "# Use the below functionality to execute your model (that you will adjust later step by step)\n",
        "# This block of code provides you the functionality to train a model. Results are printed after each epoch\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import tqdm\n",
        "\n",
        "\n",
        "def load_mnist_data(root_path='./data', batch_size=4):\n",
        "    \"\"\"\n",
        "    Loads MNIST dataset into your directory.\n",
        "    You can change the root_path to point to a already existing path if you want to safe a little bit of memory :)\n",
        "    \"\"\"\n",
        "    transform = transforms.Compose(\n",
        "        [transforms.ToTensor(),\n",
        "        transforms.Normalize((0.5), (0.5))]\n",
        "    )\n",
        "\n",
        "    trainset = torchvision.datasets.MNIST(root=root_path, train=True, download=True, transform=transform)\n",
        "    trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "\n",
        "    testset = torchvision.datasets.MNIST(root=root_path, train=False, download=True, transform=transform)\n",
        "    testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
        "\n",
        "    return trainloader, testloader\n",
        "\n",
        "\n",
        "def train_model(model, batch_size: int = 4, epochs: int = 10):\n",
        "    # we only consider the mnist train data for this example\n",
        "    train_loader, _ = load_mnist_data(root_path='./data', batch_size=batch_size)\n",
        "\n",
        "    device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "\n",
        "    model = model.to(device=device)\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.SGD(model.parameters(), lr=0.001)\n",
        "\n",
        "    iterations = 0\n",
        "    for epoch in range(epochs):\n",
        "        running_loss = 0.0\n",
        "        running_accuracy = []\n",
        "        for imgs, targets in tqdm.tqdm(train_loader, desc=f'Training iteration {epoch + 1}'):\n",
        "            iterations += 1\n",
        "            imgs, targets = imgs.to(device=device), targets.to(device=device)\n",
        "\n",
        "            # zero the parameter gradients\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # forward + backward + optimize\n",
        "            outputs = model(imgs.reshape(imgs.shape[0], -1))\n",
        "\n",
        "            loss = criterion(outputs, targets)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # print statistics\n",
        "            running_loss += loss.item()\n",
        "\n",
        "            # Calculate the Accuracy (how many of all samples are correctly classified?)\n",
        "            max_outputs = torch.max(outputs, dim=1).indices\n",
        "            accuracy = (max_outputs.detach() == targets.detach()).to(dtype=torch.float32).mean()\n",
        "            running_accuracy.append(accuracy)\n",
        "\n",
        "        print(f'Epoch {epoch + 1} finished with loss: {running_loss / len(train_loader):.3f} and accuracy {torch.tensor(running_accuracy).mean():.3f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AecHopuwWJxk"
      },
      "source": [
        "## Training progress with different weight settings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "dSxsy1sxWJxk"
      },
      "outputs": [],
      "source": [
        "# You can use this model for your tests (of course you can change the architecture a little, but it should not be necessary.)\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "\n",
        "model = nn.Sequential(\n",
        "    nn.Linear(784, 32),  # input layer (do not change the in_features size of this layer - we need it later)\n",
        "    nn.Linear(32, 32),\n",
        "    nn.Linear(32, 10)  # you can change the in_features of this layer but let the out_features at size 10 here - we need it layer\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sjSYFmp_WJxk"
      },
      "source": [
        "### Weight settings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "rllF9pHqWJxl"
      },
      "outputs": [],
      "source": [
        "# Find out how to change the weights of the layers from your neural network.\n",
        "# ATTTENTION: Write your code inside the \"with torch.no_grad():\" section! This is necessary for changing the weights of the layers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T_NT3xm1WJxl"
      },
      "source": [
        "#### Zero weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "lFuMDx_iWJxl"
      },
      "outputs": [],
      "source": [
        "# Set all weights and biases of your network to zero\n",
        "\n",
        "with torch.no_grad():\n",
        "    # Code here\n",
        "      for layer in model:\n",
        "          if hasattr(layer, \"weight\"):\n",
        "              layer.weight.fill_(0.0)\n",
        "          if hasattr(layer, \"bias\") and layer.bias is not None:\n",
        "              layer.bias.fill_(0.0)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HlBH9GdxWJxl",
        "outputId": "ec593d29-1b7e-4418-f972-789029a5314c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:00<00:00, 39.7MB/s]\n",
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 1.11MB/s]\n",
            "100%|██████████| 1.65M/1.65M [00:00<00:00, 10.0MB/s]\n",
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 12.3MB/s]\n",
            "Training iteration 1: 100%|██████████| 15000/15000 [00:42<00:00, 352.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 finished with loss: 2.302 and accuracy 0.111\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training iteration 2: 100%|██████████| 15000/15000 [00:40<00:00, 367.75it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2 finished with loss: 2.301 and accuracy 0.112\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training iteration 3: 100%|██████████| 15000/15000 [00:39<00:00, 378.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3 finished with loss: 2.301 and accuracy 0.112\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Train the network with your new settings and take a look at the results\n",
        "# Run the model training\n",
        "train_model(model=model, batch_size=4, epochs=3)\n",
        "\n",
        "# What can you observe?\n",
        "# The model fails to learn completely. With all weights set to zero, all neurons produce identical outputs regardless of the input.\n",
        "# This causes the gradients to be identical for all neurons in the same layer (symmetry problem), preventing the network from breaking\n",
        "# symmetry and learning distinct features. The loss stays around 2.302 and accuracy remains at ~0.11, similar to random guessing."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2sNSe2GLWJxl"
      },
      "source": [
        "#### Constant weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "3pPMZAmJWJxl"
      },
      "outputs": [],
      "source": [
        "# Set all weights and biases to constant numbers (e.g. 0.5)\n",
        "# How does the training progress?\n",
        "\n",
        "with torch.no_grad():\n",
        "    # Code here\n",
        "    for layer in model:\n",
        "        if hasattr(layer, \"weight\"):\n",
        "            layer.weight.fill_(0.5)\n",
        "        if hasattr(layer, \"bias\") and layer.bias is not None:\n",
        "            layer.bias.fill_(0.5)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nWhfmYP7WJxl",
        "outputId": "8acec6b2-774b-41f4-c357-1ea9c8d36825"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training iteration 1: 100%|██████████| 15000/15000 [00:42<00:00, 355.70it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 finished with loss: 68.640 and accuracy 0.101\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training iteration 2: 100%|██████████| 15000/15000 [00:41<00:00, 365.46it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2 finished with loss: 2.311 and accuracy 0.103\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training iteration 3: 100%|██████████| 15000/15000 [00:40<00:00, 372.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3 finished with loss: 2.311 and accuracy 0.105\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Train the network with your new settings and take a look at the results\n",
        "# Run the model training\n",
        "train_model(model=model, batch_size=4, epochs=3)\n",
        "\n",
        "# What can you observe?\n",
        "# The model still suffers from the symmetry problem. When all weights are initialized to the same constant value (0.5),\n",
        "# all neurons in each layer compute the same function and receive identical gradient updates. This means they remain synchronized\n",
        "# throughout training and cannot learn different features. The initial loss is very high (68.640) due to large activation values, but it\n",
        "# eventually decreases to around 2.311. However, the accuracy remains poor (~0.10), barely better than random guessing, because the network\n",
        "# cannot differentiate between different patterns in the data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hHn6n08CWJxl",
        "outputId": "4971de72-6d6a-47cf-92f0-dee1ff9306c7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "weight: tensor([[ 0.0901,  0.0901,  0.0901,  0.0901,  0.0901,  0.0901,  0.0901,  0.0901,\n",
            "          0.0901,  0.0901,  0.0901,  0.0901,  0.0901,  0.0901,  0.0901,  0.0901,\n",
            "          0.0901,  0.0901,  0.0901,  0.0901,  0.0901,  0.0901,  0.0901,  0.0901,\n",
            "          0.0901,  0.0901,  0.0901,  0.0901,  0.0901,  0.0901,  0.0901,  0.0901],\n",
            "        [-0.4969, -0.4969, -0.4969, -0.4969, -0.4969, -0.4969, -0.4969, -0.4969,\n",
            "         -0.4969, -0.4969, -0.4969, -0.4969, -0.4969, -0.4969, -0.4969, -0.4969,\n",
            "         -0.4969, -0.4969, -0.4969, -0.4969, -0.4969, -0.4969, -0.4969, -0.4969,\n",
            "         -0.4969, -0.4969, -0.4969, -0.4969, -0.4969, -0.4969, -0.4969, -0.4969],\n",
            "        [ 0.0878,  0.0878,  0.0878,  0.0878,  0.0878,  0.0878,  0.0878,  0.0878,\n",
            "          0.0878,  0.0878,  0.0878,  0.0878,  0.0878,  0.0878,  0.0878,  0.0878,\n",
            "          0.0878,  0.0878,  0.0878,  0.0878,  0.0878,  0.0878,  0.0878,  0.0878,\n",
            "          0.0878,  0.0878,  0.0878,  0.0878,  0.0878,  0.0878,  0.0878,  0.0878],\n",
            "        [ 0.0901,  0.0901,  0.0901,  0.0901,  0.0901,  0.0901,  0.0901,  0.0901,\n",
            "          0.0901,  0.0901,  0.0901,  0.0901,  0.0901,  0.0901,  0.0901,  0.0901,\n",
            "          0.0901,  0.0901,  0.0901,  0.0901,  0.0901,  0.0901,  0.0901,  0.0901,\n",
            "          0.0901,  0.0901,  0.0901,  0.0901,  0.0901,  0.0901,  0.0901,  0.0901],\n",
            "        [ 0.0853,  0.0853,  0.0853,  0.0853,  0.0853,  0.0853,  0.0853,  0.0853,\n",
            "          0.0853,  0.0853,  0.0853,  0.0853,  0.0853,  0.0853,  0.0853,  0.0853,\n",
            "          0.0853,  0.0853,  0.0853,  0.0853,  0.0853,  0.0853,  0.0853,  0.0853,\n",
            "          0.0853,  0.0853,  0.0853,  0.0853,  0.0853,  0.0853,  0.0853,  0.0853],\n",
            "        [ 0.0806,  0.0806,  0.0806,  0.0806,  0.0806,  0.0806,  0.0806,  0.0806,\n",
            "          0.0806,  0.0806,  0.0806,  0.0806,  0.0806,  0.0806,  0.0806,  0.0806,\n",
            "          0.0806,  0.0806,  0.0806,  0.0806,  0.0806,  0.0806,  0.0806,  0.0806,\n",
            "          0.0806,  0.0806,  0.0806,  0.0806,  0.0806,  0.0806,  0.0806,  0.0806],\n",
            "        [-0.0104, -0.0104, -0.0104, -0.0104, -0.0104, -0.0104, -0.0104, -0.0104,\n",
            "         -0.0104, -0.0104, -0.0104, -0.0104, -0.0104, -0.0104, -0.0104, -0.0104,\n",
            "         -0.0104, -0.0104, -0.0104, -0.0104, -0.0104, -0.0104, -0.0104, -0.0104,\n",
            "         -0.0104, -0.0104, -0.0104, -0.0104, -0.0104, -0.0104, -0.0104, -0.0104],\n",
            "        [ 0.0919,  0.0919,  0.0919,  0.0919,  0.0919,  0.0919,  0.0919,  0.0919,\n",
            "          0.0919,  0.0919,  0.0919,  0.0919,  0.0919,  0.0919,  0.0919,  0.0919,\n",
            "          0.0919,  0.0919,  0.0919,  0.0919,  0.0919,  0.0919,  0.0919,  0.0919,\n",
            "          0.0919,  0.0919,  0.0919,  0.0919,  0.0919,  0.0919,  0.0919,  0.0919],\n",
            "        [-0.0064, -0.0064, -0.0064, -0.0064, -0.0064, -0.0064, -0.0064, -0.0064,\n",
            "         -0.0064, -0.0064, -0.0064, -0.0064, -0.0064, -0.0064, -0.0064, -0.0064,\n",
            "         -0.0064, -0.0064, -0.0064, -0.0064, -0.0064, -0.0064, -0.0064, -0.0064,\n",
            "         -0.0064, -0.0064, -0.0064, -0.0064, -0.0064, -0.0064, -0.0064, -0.0064],\n",
            "        [-0.0122, -0.0122, -0.0122, -0.0122, -0.0122, -0.0122, -0.0122, -0.0122,\n",
            "         -0.0122, -0.0122, -0.0122, -0.0122, -0.0122, -0.0122, -0.0122, -0.0122,\n",
            "         -0.0122, -0.0122, -0.0122, -0.0122, -0.0122, -0.0122, -0.0122, -0.0122,\n",
            "         -0.0122, -0.0122, -0.0122, -0.0122, -0.0122, -0.0122, -0.0122, -0.0122]])\n",
            "bias: tensor([ 0.2036, -1.0370,  0.1984,  0.2035,  0.1928,  0.1820, -0.0494,  0.2077,\n",
            "        -0.0451, -0.0564])\n"
          ]
        }
      ],
      "source": [
        "# Let us also take a look at the gradient of the output layer\n",
        "# Access the gradients at the output layer of your model and analyze them\n",
        "\n",
        "# We first input some random values\n",
        "# forward + backward\n",
        "outputs = model(torch.randn(size=(1,784)))\n",
        "loss = nn.CrossEntropyLoss()(outputs, torch.tensor([1]))\n",
        "loss.backward()\n",
        "\n",
        "\n",
        "# Code here\n",
        "for name, param in model[-1].named_parameters():\n",
        "    if param.grad is not None:\n",
        "        print(f\"{name}: {param.grad}\")\n",
        "\n",
        "# What can you observe?\n",
        "# The gradients show the symmetry problem clearly. All 32 values within each row of the weight gradient are identical\n",
        "# (e.g., all 0.0901 in the first row, all -0.4969 in the second row). This demonstrates that when weights are initialized identically,\n",
        "# all neurons in a layer receive the same gradient updates, making them functionally identical throughout training. The bias gradients show different\n",
        "# values between output classes, but this alone is insufficient for the network to learn complex patterns."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xj0Da8qlWJxl"
      },
      "source": [
        "#### Unusual weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Y0KcYr0jWJxl"
      },
      "outputs": [],
      "source": [
        "# Set some weights (around 50%) of every model of the model to some weird value, e. g. extremely high (> 10.0) or extremely low (< 1e-7).\n",
        "# How does the training progress?\n",
        "# Can your model also diverge instead of converge because the weights were way to high or low?\n",
        "\n",
        "with torch.no_grad():\n",
        "    # Code here\n",
        "    for layer in model:\n",
        "        if hasattr(layer, \"weight\"):\n",
        "            shape = layer.weight.shape\n",
        "            flat = layer.weight.flatten()\n",
        "            split = flat.shape[0] // 2\n",
        "            flat[:split].fill_(10.0)\n",
        "            flat[split:].fill_(1e-7)\n",
        "            layer.weight.data = flat.reshape(shape)\n",
        "        if hasattr(layer, \"bias\") and layer.bias is not None:\n",
        "            shape = layer.bias.shape\n",
        "            flat = layer.bias.flatten()\n",
        "            split = flat.shape[0] // 2\n",
        "            flat[:split].fill_(10.0)\n",
        "            flat[split:].fill_(1e-7)\n",
        "            layer.bias.data = flat.reshape(shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tORHu5gfWJxl",
        "outputId": "64fe1347-e16b-4d6c-8254-1211f56cd5a5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training iteration 1: 100%|██████████| 15000/15000 [00:40<00:00, 367.09it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 finished with loss: nan and accuracy 0.099\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training iteration 2: 100%|██████████| 15000/15000 [00:40<00:00, 366.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2 finished with loss: nan and accuracy 0.099\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training iteration 3: 100%|██████████| 15000/15000 [00:42<00:00, 356.26it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3 finished with loss: nan and accuracy 0.099\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training iteration 4: 100%|██████████| 15000/15000 [00:42<00:00, 355.41it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4 finished with loss: nan and accuracy 0.099\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training iteration 5: 100%|██████████| 15000/15000 [00:40<00:00, 374.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5 finished with loss: nan and accuracy 0.099\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Train the network with your new settings and take a look at the results\n",
        "# Run the model training\n",
        "train_model(model=model, batch_size=4, epochs=5)\n",
        "\n",
        "# What can you observe?\n",
        "# The model diverges completely, producing NaN losses. When half the weights are initialized to extremely high values (10.0)\n",
        "# and the other half to extremely low values (1e-7), the forward pass produces numerical instability. The large weights cause activations to explode,\n",
        "# leading to overflow in the loss calculation. Once NaN appears, it propagates through all subsequent calculations, making training impossible.\n",
        "# The accuracy stays at random level (0.099) because the network produces invalid predictions. This demonstrates the critical importance of proper\n",
        "# weight initialization for numerical stability.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G7h8OMEIWJxl"
      },
      "source": [
        "## Weight initialization techniques"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "2uq254rPWJxl",
        "outputId": "3cffe288-9975-455d-a5eb-70f6021c7415"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# We now take a closer look to the sigmoid activation function.\n",
        "# Where does the sigmoid function create small gradients and where are the biggest gradients?\n",
        "\n",
        "# Explanation here\n",
        "# The sigmoid function creates the smallest gradients at the extreme values (when x approaches -5 or +5), where the curve flattens out\n",
        "# and becomes nearly horizontal (approaching 0 or 1). This is known as the \"vanishing gradient problem.\" The biggest gradients occur at the center\n",
        "# of the curve (around x = 0), where the sigmoid has its steepest slope. At x = 0, the gradient is approximately 0.25, which is the maximum.\n",
        "# As we move away from zero in either direction, the gradients decrease exponentially, becoming very close to zero at |x| > 3.\n",
        "\n",
        "# Now lets plot some different activation function methods\n",
        "# Use matplotlib and plot the sigmoid activation function into the plot.\n",
        "# Create 1000 sample points from x-values [-5.0, 5.0] and create y = Sigmoid(x) and plot the result. (The result should simply be the sigmoid curve)\n",
        "# You can use the Sigmoid function from PyTorch here!\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# Code here\n",
        "x = np.linspace(-5.0, 5.0, 1000)\n",
        "y = torch.sigmoid(torch.tensor(x))\n",
        "plt.plot(x, y, label=\"Sigmoid curve\")\n",
        "\n",
        "\n",
        "# Now lets plot the kaiming normal weight initialization into the plot\n",
        "# Create 1000 points (x) sampled from the kaiming_normal_ (pytorch function) and create y = Sigmoid(kaiming_normal(1000)) and plot the result into the same plot as before.\n",
        "# Use a different color for plotting the results\n",
        "\n",
        "\n",
        "# Code here\n",
        "kaiming_x = torch.empty(1000).normal_(mean=0.0, std=np.sqrt(2/784))\n",
        "kaiming_y = torch.sigmoid(kaiming_x)\n",
        "plt.plot(kaiming_x.numpy(), kaiming_y.numpy(), 'o', ms=1, label=\"Kaiming Normal\")\n",
        "\n",
        "\n",
        "# Now plot a random normal (torch.randn) weight initialization into the plot\n",
        "# Create 1000 points (x) sampled from the randn (pytorch function) and create y = Sigmoid(randn(1000)) and plot the result into the same plot as before.\n",
        "# Use a different color for plotting the results\n",
        "\n",
        "\n",
        "# Code here\n",
        "randn_x = torch.randn(1000)\n",
        "randn_y = torch.sigmoid(randn_x)\n",
        "plt.plot(randn_x.numpy(), randn_y.numpy(), 'o', ms=1, label=\"Normal\")\n",
        "\n",
        "\n",
        "# Now plot a xavier_normal weight initialization into the plot\n",
        "# Create 1000 points (x) sampled from the xavier_normal_ (pytorch function) and create y = Sigmoid(xavier_normal_(1000)) and plot the result into the same plot as before.\n",
        "# Use a different color for plotting the results\n",
        "\n",
        "\n",
        "# Code here\n",
        "xavier_x = torch.empty(1000, 1)\n",
        "nn.init.xavier_normal_(xavier_x)\n",
        "xavier_x = xavier_x.flatten()\n",
        "xavier_y = torch.sigmoid(xavier_x)\n",
        "plt.plot(xavier_x.numpy(), xavier_y.numpy(), 'o', ms=1, label=\"Xavier Normal\")\n",
        "\n",
        "\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# Which weight initialization technique is best when using sigmoid activation function?\n",
        "\n",
        "# Answer here\n",
        "# Xavier Normal initialization is the best choice for sigmoid activation functions. Looking at the plot, Xavier initialization\n",
        "# concentrates most weight values in the linear region of the sigmoid (around x = 0), where gradients are largest. This helps avoid the vanishing\n",
        "# gradient problem that occurs at the saturation regions (extreme values).\n",
        "\n",
        "# Kaiming Normal initialization, designed for ReLU activations, tends to produce slightly larger values that push some activations toward the\n",
        "# flatter regions of sigmoid, resulting in smaller gradients. Standard Normal (randn) produces even more extreme values, causing many neurons to\n",
        "# saturate and have very small gradients.\n",
        "\n",
        "# Xavier initialization keeps the variance of activations and gradients consistent across layers, which is optimal for sigmoid and tanh activation functions,\n",
        "# leading to more stable and efficient training.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-SRHhUObWJxm"
      },
      "source": [
        "## Be creative and test some other weight initialization techniques! - There is so much to explore!"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "25301cabe4c6f833fd20f15b1b22933971919908771eb627a83fe325b4fb6671"
      }
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}